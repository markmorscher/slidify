boxplot(sim_streak)
load(url("http://www.openintro.org/stat/data/ames.RData"))
str(ames)
area = ames$Gr.Liv.Area
price = ames$SalePrice
ls()
summary(area)
summary(price)
str(are)
str(area)
hist(area)
boxplot(area)
?IQR
IQR(area)
samp0 = sample(area, 50)
str(samp0)
summary(samp0)
samp1 = sample(area, 50)
summary(samp1)
mean(samp1)
samp2 = sample(area,1000)
summary(samp2)
sample_means50 <- rep(NA, 5000)for (i in 1:5000) {samp <- sample(area, 50)sample_means50[i] <- mean(samp)}hist(sample_means50)
sample_means50 <- rep(NA, 5000)for (i in 1:5000) {samp <- sample(area, 50)sample_means50[i] <- mean(samp)}hist(sample_means50)
?rep
?NA
sample_means50 <- rep(NA, 5000)
for (i in 1:5000) {samp <- sample(area, 50)sample_means50[i] <- mean(samp)}hist(sample_means50)
for (i in 1:5000) {
samp <- sample(area, 50)
sample_means50[i] <- mean(samp)
}
hist(sample_means50)
sample_means_small <- rep(NA, 100)
samp <- sample(area, 50)
sample_means_small <- rep(NA, 100)
for (i in 1:100) {
samp <- sample(area, 50)
sample_means_small[i] <- mean(samp)
}
hist(sample_means_small)
sample_means_small
summary(sample_means50)
sample_means50 <- rep(NA, 5000)
sample_means10 <- rep(NA, 5000)
sample_means100 <- rep(NA, 5000)
for (i in 1:5000) {
samp <- sample(area, 50)
sample_means50[i] <- mean(samp)
samp <- sample(area, 10)
sample_means10[i] <- mean(samp)
samp <- sample(area, 50)
sample_means100[i] <- mean(samp)
}
summary(sample_means10)
summary(sample_means50)
summary(sample_means100)
par(mfrow = c(3, 1))
xlimits = range(sample_means10)
hist(sample_means10, breaks = 20, xlim = xlimits)
hist(sample_means50, breaks = 20, xlim = xlimits)
hist(sample_means100, breaks = 20, xlim = xlimits)
sampP <- sample(price, 50)
summary(sampP)
sample_means50 <- rep(NA, 5000)
sample_means150 <- rep(NA, 5000)
sample_means100 <- rep(NA, 5000)
for (i in 1:5000) {
samp <- sample(price, 50)
sample_means50[i] <- mean(samp)
samp <- sample(price, 150)
sample_means150[i] <- mean(samp)
#  samp <- sample(area, 50)
#  sample_means100[i] <- mean(samp)
}
par(mfrow = c(2, 1))
xlimits = range(sample_means50)
hist(sample_means150, breaks = 20, xlim = xlimits)
hist(sample_means50, breaks = 20, xlim = xlimits)
population = amies$Gr.Liv.Area
population = ames$Gr.Liv.Area
samp = sample(population, 60)
summary(samp)
mean(samp)
summary(population)
sample_mean = mean(samp)
sample_mean
se <- sd(samp)/sqrt(60)lower <- sample_mean - 1.96 * seupper <- sample_mean + 1.96 * sec(lower, upper)
se = sd(samp)/sqrt(60)
lower = sample_mean - 1.96*se
upper = sample_mean + 1.96*se
c(lower,upper)
samp_mean <- rep(NA, 50)
samp_sd <- rep(NA, 50)
n <- 60
for(i in 1:50){
samp <- sample(population, n) # obtain a sample of size n = 60 from the population
samp_mean[i] <- mean(samp) # save sample mean in ith element of samp_mean
samp_sd[i] <- sd(samp) # save sample sd in ith element of samp_sd
}
lower <- samp_mean - 1.96 * samp_sd/sqrt(n)
upper <- samp_mean + 1.96 * samp_sd/sqrt(n)
c(lower[1], upper[1])
plot_ci(lower, upper, mean(population))
lower <- samp_mean - 2.33 * samp_sd/sqrt(n)
upper <- samp_mean + 2.33 * samp_sd/sqrt(n)
c(lower[1], upper[1])
plot_ci(lower, upper, mean(population))
load(url("http://bit.ly/dasi_nc"))
str(nc)
summary(nc)
hist(nc$gained)
gained_clean = na.omit(nc$gained)
summary(gained_clean)
str(gained_clean)
boot_means = rep(NA, 100)
for(i in 1:100){
boot_sample = sample(gained_clean, n, replace = TRUE)
boot_means[i] = mean(boot_sample)
}
boot_means = rep(NA, 100)
for(i in 1:100){
boot_sample = sample(gained_clean, 1000, replace = TRUE)
boot_means[i] = mean(boot_sample)
}
hist(boot_means)
?sd
sd(boot_means)
source("http://bit.ly/dasi_inference")
inference(nc$gained, type = "ci", method = "simulation", conflevel = 0.9, est = "mean",          boot_method = "perc")
inference(nc$gained, type = "ci", method = "simulation", conflevel = 0.9, est = "mean",          boot_method = "perc")
inference(nc$gained, type = "ci", method = "simulation", conflevel = 0.9, est = "mean",boot_method = "perc")
inference(nc$gained, type = "ci", method = "simulation", conflevel = 0.95, est = "mean",boot_method = "perc")
inference(nc$gained, type = "ci", method = "simulation", conflevel = 0.95, est = "mean",boot_method = "se")
inference(nc$gained, type = "ci", method = "simulation", conflevel = 0.95, est = "median",boot_method = "se")
str(nc)
plot(nc$gained, nc$habit)
summary(nc)
boxplot(weight ~ habit, data=nc)
by(nc$weight, nc$habit, mean)
inference(y = nc$weight, x = nc$habit, est = "mean", type = "ht", null = 0, alternative = "twosided", method = "theoretical")
inference(y = nc$weight, x = nc$habit, est = "mean", type = "ci", null = 0, alternative = "twosided", method = "theoretical")
str(nc)
table(nc$mature, nc$mage)
load(url("http://bit.ly/dasi_gss_ws_cl"))
str(gss)
summary(gss)
boxplot(wordsum ~ class, data=gss)
inference(y = gss$wordsum, x = gss$class, est = "mean", type = "ht", alternative = "greater", method = "theoretical")
source("http://bit.ly/dasi_inference")
inference(y = gss$wordsum, x = gss$class, est = "mean", type = "ht", alternative = "greater", method = "theoretical")
load("~/R/MIT R Code/Week 3/FinalWeek3Hmwk.RData")
source("http://bit.ly/dasi_inference")
load(url("http://www.openintro.org/stat/data/atheism.RData"))
ls()
str(atheism)
summary(atheism)
us12 = subset(atheism, atheism$nationality == "United States" & atheism$year ==                  "2012")
us12 = subset(atheism, atheism$nationality == "United States" & atheism$year =="2012")
ls()
str(us12)
summary(us12)
50/1002
inference(us12$response, est = "proportion", type = "ci", method = "theoretical",success = "atheist")
sqrt(.0499/1002)
n <- 1000
p <- seq(0, 1, 0.01)
me <- 2 * sqrt(p * (1 - p)/n)
plot(me ~ p)
us12 = subset(atheism, atheism$nationality == "Spain")
us12 = subset(atheism, atheism$nationality == "United States" & atheism$year =="2012")
spain = subset(atheism, atheism$nationality == "Spain")
str(spain)
summary(spain)
inference(spain$response~year, est = "proportion", type = "ci", method = "theoretical",success = "atheist")
inference(spain$response, est = "proportion", type = "ci", method = "theoretical",success = "atheist")
str(inference)
inference(spain$response, x=year, est = "proportion", type = "ci", method = "theoretical",success = "atheist")
inference(spain$response, x=spain$year, est = "proportion", type = "ci", method = "theoretical",success = "atheist")
us = subset(atheism, atheism$nationality == "United States")
inference(us$response, x=us$year, est = "proportion", type = "ci", method = "theoretical",success = "atheist")
install.packages("KernSmooth")
library(KernSmooth)
install.packages("RMySQL")
library(RMySQL)
ucscDB = dbConnect(MySQL(), user="genome", host="genome-mysql.cse.ucsc.edu")
result = dbGetQuery(ucscDB, "show databases;")
dbDisconnect(ucscDB)
result
hg19 = dbConnect(MySQL(), user="genome", db="hg19" host="genome-mysql.cse.ucsc.edu")
hg19 = dbConnect(MySQL(), user="genome", db="hg19", host="genome-mysql.cse.ucsc.edu")
allTables = dbListTables(hg19)
length(allTables)
head(allTables)
dbListFields(hg19, "affyU133Plus2")
dbGetQuery(hg19, "select count(*) from affyU133Plus2")
affyData = dbReadTable(hg19, "affyU133Plus2")
head(affyData)
ls()
str(affyData)
query = dbSendQuery(hg19, "select * from affyU133Plus2 where misMathes between 1 and 3")
query = dbSendQuery(hg19, "select * from affyU133Plus2 where misMatches between 1 and 3")
affyMis = fetch(query)
str(affyMis)
quantile(affyMis$misMatches)
affyMisSmall = fetch(query,n=10)
dbClearResult(query)
dim(affyMisSmall)
head(affyMisSmall)
str(affyMisSmall)
dbDisconnect(hg19)
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(rhdf5)
created = h5createFile("expample.h5")
created
created = h5createGroup("expample.h5", foo)
created = h5createGroup("expample.h5", "foo")
created = h5createGroup("expample.h5", "baa")
created = h5createGroup("expample.h5", "foo/foobaa")
h5ls("example.h5")
h5ls("expample.h5")
A = matrix(1:10, nr=5, nc=2)
h5write(A, "expample.h5", "foo/A")
h5ls("expample.h5")
ls
ls()
?end
?return
getwd()
if (!file.exists("UCI HAR Dataset")) {
print("Working directory must have the unzipped UCI HAR Dataset directory and files.")
return()
}
?stop
?quit
?exit
?while
??while
?for
?quit
while (!file.exists("UCI HAR Dataset")) {
print("Working directory must have the unzipped UCI HAR Dataset directory and files.")
print("Please set proper working directory or unzip files.")
}
while (!file.exists("UCI HAR Dataset")) {
print("Working directory must have the unzipped UCI HAR Dataset directory and files.")
print("Please set proper working directory or unzip files.")
quit()
}
source('~/R/Data Science Specialization/Getting and Cleaning Data/run_analysis.R', echo=TRUE)
library(nlme)
str(BodyWeight)
library(lattice)
?lattice
library(datasets)
data(airquality)
library(ggplot2)
?qplot
choose(5,4)*.5^5 + choose(5,5)*.5^5
ppois(10, lambda = 5*3)
choose(9,3)
a = c(140, 138,150,148,135)
a
str(a)
mean(a)
std(a)
summary(a)
stddev(a)
sd(a)
b = c(132, 135, 151, 146, 130)
mean(b)
sd(b)
t.test(a -b)
choose(4,3) * .5 ^ 4 + choose(4,4) * .5 ^ 4
pbinom(2, size = 4, prob = .5, lower.tail = FALSE)
10/1787
ppois(9, 17.9, lower.tail = FALSE)
ppois(9, 17.9, upper.tail = FALSE)
ppois(9, 17.9, lower.tail = FALSE)
pnorm(-0.855, lower.tail=FALSE)
pnorm(-0.855, lower.tail=TRUE)
power.t.test(power = .9, delta = .01, sd=.04, type="one.sample", alt = "one.sided")$n
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~x)
lm(y~x - 1)
data(mtcars)
str(mtcars)
lm(mpg~wt)
lm(mpg~wt, data=mtcars)
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
mean(x)
8.58 - mean(x)
x
sd(x)
(8.58 - mean(x))/sd(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
lm(y~x)
mean(x)
lm(x~y)
-1.713/-.04462
var(y)
var(x)
var(y)/var(x)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
lm(y~x)
fit = lm(y~x)
str(fit)
summary(fit)
fit$residuals
sd(fit$residuals)
sqrt(0.3552)
fit$df
load(mtcars)
use(mtcars)
data(mtcars)
str(mtcars)
mtfit = lm(mpg~wt)
mtfit = lm(mpg~wt, data = mtcars)
summary(mtfit)
sumCoef <- summary(mtfit)$coefficients
sumCoef
sumCoef[2,1] + c(-1, 1) * qt(.975, df = mtfit$df) * sumCoef[2, 2]
help(mtcars)
mean(mtcars$wt)
37.285 - 6.486*3.217
mtfit$df
-4.2026 * 3
sumCoef[1,1] + c(-1, 1) * qt(.975, df = mtfit$df) * sumCoef[1, 2]
33.45 - 6.486*3.217
mtfit2 = lm(mpg ~ (wt - mean(wt)), data = mtcars)
mtfit2 = lm(mpg ~ (wt - mean(mtcars$wt)), data = mtcars)
mtfit2 = lm(mpg ~ I(wt - mean(mtcars$wt)), data = mtcars)
summary(mtfit2)
sumCoef2 <- summary(mtfit)$coefficients
sumCoef2 <- summary(mtfit2)$coefficients
sumCoef2[1,1] + c(-1, 1) * qt(.975, df = mtfit2$df) * sumCoef2[1, 2]
sumCoef2[2,1] + c(-1, 1) * qt(.975, df = mtfit2$df) * sumCoef2[2, 2]
21.19 - 4.202(3 - mean(mtcars$wt))
21.19 - 4.202*(3 - mean(mtcars$wt))
4.202*(3 - mean(mtcars$wt))
20.09 - 4.202*(3 - mean(mtcars$wt))
library(AppliedPredictiveModeling)
install.packages(AppliedPredictiveModeling)
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[ -inTrain,]
str(training)
training[]
training[1,]
training[,1]
plot(training$CompressiveStrength)
qplot(CompressiveStrength, colour=FlyAsh, data=training)
qplot(CompressiveStrength, colour=Age, data=training)
library(Hmisc)
?cut2
qplot(CompressiveStrength, colour=cut2(Age,g=4, data=training)
qplot(CompressiveStrength, colour=cut2(Age,g=4), data=training)
plot(training$CompressiveStrength)
qplot(training$CompressiveStrength)
plot(training$CompressiveStrength)
?plot
?qplot
qplot(training$CompressiveStrength, index)
qplot(training$CompressiveStrength, row)
head(training)
cutAge = cut2(training$Age, g=4)
plot(training$CompressiveStrength)
plot(training$CompressiveStrength, col = cutAge)
qplot(training$CompressiveStrength ~ )
cutAge
table(cutAge)
plot(training$CompressiveStrength, col = cut2(training$Age, g=4))
plot(training$CompressiveStrength, col = cut2(training$FlyAsh, g=4))
plot(training$CompressiveStrength, col = cut2(training$Age, g=4))
plot(training$CompressiveStrength, col = cut2(training$FlyAsh, g=4))
plot(training$Superplasticizer)
summary(training$Superplasticizer)
boxplot(training$Superplasticizer)
histogram(training$Superplasticizer)
str(training$Superplasticizer)
summary(training)
histogram(log10(training$Superplasticizer)
)
histogram(training$Superplasticizer)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
str(training)
colnames(training)
data = training[,58:69]
str(data)
M = abs(cor(data))
diag(M = 0)
diag(M) = 0
which(M > 0.8, arr.ind=T)
preProc = preProcess(data, method = "pca", thresh = 0.9)
preProc
preProc = preProcess(data, method = "pca", thresh = 0.8)
preProc
trainPC = predict(preProc, data)
modelFit = train(data$diagnosis ~ ., method="glm", data=trainPC )
modelFit = train(training$diagnosis ~ ., method="glm", data=trainPC )
testPC = predict(preProc, testing)
dataTrain = data
dataTrain$diagnosis = training$diagnosis
modelFit
nonpcaMod = train(diagnosis ~ ., method = "glm", data = dataTrain)
print(nonpacMod$finalModel)
print(nonpcaMod$finalModel)
nonpcaMod
nonpcaPred = predict(nonpcaMod, newdata = testing)
confusionMatrix(nonpcaPred, testing$diagnosis)
data(mtcars)
ls()
str(mtcars)
fit = lm(mpg ~ cyl + wt, data=mtcars)
fit
?lm
4*1.508
?lom
?lm
fit2 = lim(mps ~ cyl*wt, data=mtcars)
fit2 = lm(mps ~ cyl*wt, data=mtcars)
fit2 = lm(mpg ~ cyl*wt, data=mtcars)
fit2
4*1.508
4*3.8032 - 4*0.8084
4*3.8032
fit3 = lm(mpg ~ cyl, data=mtcars)
fit3
library(mtcars)
data(mtcars)
ls()
str(mtcars)
mtcars$cylF = as.factor(mtcars$cyl)
str(mtcars)
summary(mtcars)
fit = lm(mpg ~ cylF + wt, data=mtcars)
fit
summary(fit)
fit2 = lm(mpg ~ cylF, data=mtcars)
fit2
fit3 = lm(mpg ~ cylF + wt + cylF*wt, data=mtcars)
fit3
summary(fit3)
?anova
comp = anova(fit, fit3)
comp
anova(fit3, fit)
fit4 = lm(mpg ~ cylF + wt + cyl*wt, data=mtcars)
comp = anova(fit, fit4)
comp
fit5 = lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
summary(fit5)
?lm
?mtcars
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit6 = lm(y~x)
round(hatvalues(fit6))[1:5], 3)
round(hatvalues(fit6)[1:5], 3)
round(dfbetas(fit)[1:5, 2], 3)
round(dfbetas(fit6)[1:5, 2], 3)
fit
fit3
fit4
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y = as.factor(vowel.train$y)
vowel.test$y = as.factor(vowel.test$y)
library(caret)
?varlmp
fit = train(y ~ ., data=vowel.train, method="rf", prox=TRUE)
varImp(fit)
varImp(fit$finalModel)
sort(varImp(fit$finalModel))
str(vowel.train)
fit
devtools::install_github('rstudio/shinyapps')
library(shinyapps)
library(shiny)
install.packages('shiny')
setwd("~/R/Data Science Specialization/Developing Data Products/shinyProject")
runApp()
library(shiny)
runApp()
shinyapps::setAccountInfo(name='markmorscher', token='508191414BF5DEFCF609C9C24FC13DAA', secret='/sw8Dp2MXK4ElRrW9Kp8JwwrNi9Ae36tiTT9bL74')
deployApp()
data()
runApp()
deployApp()
install_github('slidify', 'ramnathv')
library(devtools)
install_github('slidify', 'ramnathv')
install_github('slidifyLibraries','ramnathv')
library(slidify)
setwd("~/R/Data Science Specialization/Developing Data Products/shinyProject")
author("feed_chicks")
